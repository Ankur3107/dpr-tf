{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q faiss-cpu","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://dl.fbaipublicfiles.com/dpr/data/retriever/biencoder-nq-adv-hn-train.json.gz\n!gunzip biencoder-nq-adv-hn-train.json.gz","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nimport random\nfrom dataclasses import dataclass\nimport numpy as np\nfrom transformers import AutoTokenizer\nimport os\nimport uuid\nfrom transformers import AutoConfig, AutoTokenizer, TFAutoModel\nimport tensorflow as tf\nimport numpy as np\nfrom tensorflow import keras\nfrom tqdm import tqdm_notebook","metadata":{"execution":{"iopub.status.busy":"2021-06-26T17:02:48.242356Z","iopub.execute_input":"2021-06-26T17:02:48.242796Z","iopub.status.idle":"2021-06-26T17:02:51.165134Z","shell.execute_reply.started":"2021-06-26T17:02:48.242739Z","shell.execute_reply":"2021-06-26T17:02:51.164080Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\nprint(resolver.master())\ntf.config.experimental_connect_to_cluster(resolver)\ntf.tpu.experimental.initialize_tpu_system(resolver)\nstrategy = tf.distribute.experimental.TPUStrategy(resolver)\nstrategy","metadata":{"execution":{"iopub.status.busy":"2021-06-26T17:02:51.177281Z","iopub.execute_input":"2021-06-26T17:02:51.177586Z","iopub.status.idle":"2021-06-26T17:02:56.552722Z","shell.execute_reply.started":"2021-06-26T17:02:51.177559Z","shell.execute_reply":"2021-06-26T17:02:56.551854Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"grpc://10.0.0.2:8470\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.distribute.tpu_strategy.TPUStrategy at 0x7fc11130d310>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Data Preparation","metadata":{}},{"cell_type":"code","source":"def read_dpr_json(file, max_samples=None, num_hard_negatives=1, num_positives=1, shuffle_negatives=True, shuffle_positives=False):\n    \n    dicts = json.load(open(file, encoding='utf-8'))\n\n    #if max_samples:\n    #    dicts = random.sample(dicts, min(max_samples, len(dicts)))\n\n    # convert DPR dictionary to standard dictionary\n    query_json_keys = [\"question\", \"questions\", \"query\"]\n    positive_context_json_keys = [\"positive_contexts\", \"positive_ctxs\", \"positive_context\", \"positive_ctx\"]\n    hard_negative_json_keys = [\"hard_negative_contexts\", \"hard_negative_ctxs\", \"hard_negative_context\", \"hard_negative_ctx\"]\n    standard_dicts = []\n    for i in tqdm_notebook(range(len(dicts))):\n        dict = dicts[i]\n        sample = {}\n        positive_passages = []\n        negative_passages = []\n        for key, val in dict.items():\n            if key in query_json_keys:\n                sample[\"query\"] = val\n            elif key in positive_context_json_keys:\n                if shuffle_positives:\n                    random.shuffle(val)\n                for passage in val[:num_positives]:\n                    positive_passages.append({\n                        \"title\": passage[\"title\"],\n                        \"text\": passage[\"text\"],\n                        \"label\": \"positive\"})\n            elif key in hard_negative_json_keys:\n                if shuffle_negatives:\n                    random.shuffle(val)\n                for passage in val[:num_hard_negatives]:\n                    negative_passages.append({\n                        \"title\": passage[\"title\"],\n                        \"text\": passage[\"text\"],\n                        \"label\": \"hard_negative\"})\n        sample[\"passages\"] = positive_passages + negative_passages\n        if len(sample[\"passages\"]) == num_positives+num_hard_negatives:\n            standard_dicts.append(sample)\n        if max_samples:\n            if len(standard_dicts)==max_samples:\n                break\n    return standard_dicts","metadata":{"execution":{"iopub.status.busy":"2021-06-26T17:02:56.553797Z","iopub.execute_input":"2021-06-26T17:02:56.554199Z","iopub.status.idle":"2021-06-26T17:02:56.565137Z","shell.execute_reply.started":"2021-06-26T17:02:56.554169Z","shell.execute_reply":"2021-06-26T17:02:56.564231Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"dicts = read_dpr_json(\"biencoder-nq-adv-hn-train.json\",max_samples=60000, num_hard_negatives=3)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T17:02:56.566601Z","iopub.execute_input":"2021-06-26T17:02:56.567085Z","iopub.status.idle":"2021-06-26T17:03:15.403967Z","shell.execute_reply.started":"2021-06-26T17:02:56.567044Z","shell.execute_reply":"2021-06-26T17:03:15.403078Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n  del sys.path[0]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/69639 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fe88e78a6b440729d05601c23a1a180"}},"metadata":{}}]},{"cell_type":"code","source":"@dataclass\nclass DataConfig:\n    num_positives = 1\n    num_hard_negatives = 3\n\ndata_config = DataConfig()\n\nclass ModelConfig:\n    passage_max_seq_len = 156\n    query_max_seq_len = 64\n    batch_size_per_replica = 128\n    epochs = 40\n    learning_rate = 2e-5\n    num_warmup_steps = 1234\n    dropout = 0.1\n    model_name = \"google/bert_uncased_L-4_H-512_A-8\"\n    \nmodel_config = ModelConfig()","metadata":{"execution":{"iopub.status.busy":"2021-06-26T17:03:19.351339Z","iopub.execute_input":"2021-06-26T17:03:19.352044Z","iopub.status.idle":"2021-06-26T17:03:19.407014Z","shell.execute_reply.started":"2021-06-26T17:03:19.352009Z","shell.execute_reply":"2021-06-26T17:03:19.405589Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_config.model_name)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T17:03:23.145813Z","iopub.execute_input":"2021-06-26T17:03:23.146187Z","iopub.status.idle":"2021-06-26T17:03:25.925352Z","shell.execute_reply.started":"2021-06-26T17:03:23.146159Z","shell.execute_reply":"2021-06-26T17:03:25.924062Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def encode_query_passage(tokenizer, dicts, model_config, data_config):\n    passage_input_ids = []\n    passage_token_type_ids = []\n    passage_attention_mask = []\n    \n    queries = []\n    for i in tqdm_notebook(range(len(dicts))):\n        di = dicts[i]\n        di_query = di['query']\n        di_passages = di['passages']\n        di_positives = [(pi['title'],pi['text']) for pi in di_passages if pi['label']==\"positive\"]\n        di_negatives = [(ni['title'],ni['text']) for ni in di_passages if ni['label']==\"hard_negative\"]\n        \n        if data_config.num_positives == len(di_positives) and data_config.num_hard_negatives == len(di_negatives):\n            \n            queries.append(di_query)\n            i_passages = di_positives + di_negatives\n            i_passage_inputs = tokenizer.batch_encode_plus(\n                        i_passages,\n                        max_length=model_config.passage_max_seq_len,\n                        add_special_tokens=True,\n                        truncation=True,\n                        truncation_strategy='longest_first',\n                        padding=\"max_length\",\n                        return_token_type_ids=True,\n                    )\n            passage_input_ids.append(np.array(i_passage_inputs['input_ids']))\n            passage_token_type_ids.append(np.array(i_passage_inputs['token_type_ids']))\n            passage_attention_mask.append(np.array(i_passage_inputs['attention_mask']))\n    \n    print(\"len queries:\", len(queries))\n    query_inputs = tokenizer.batch_encode_plus(\n                    queries,\n                    max_length=model_config.query_max_seq_len,\n                    add_special_tokens=True,\n                    truncation=True,\n                    truncation_strategy='longest_first',\n                    padding=\"max_length\",\n                    return_token_type_ids=True,\n                    return_tensors=\"np\"\n                    )\n    \n    \n    return {\n        \"query_input_ids\": query_inputs['input_ids'],\n        \"query_token_type_ids\": query_inputs['token_type_ids'],\n        \"query_attention_mask\": query_inputs['attention_mask'],\n        \"passage_input_ids\": np.array(passage_input_ids),\n        \"passage_token_type_ids\": np.array(passage_token_type_ids),\n        \"passage_attention_mask\": np.array(passage_attention_mask)\n    } ","metadata":{"execution":{"iopub.status.busy":"2021-06-26T17:03:28.697649Z","iopub.execute_input":"2021-06-26T17:03:28.698013Z","iopub.status.idle":"2021-06-26T17:03:28.709781Z","shell.execute_reply.started":"2021-06-26T17:03:28.697984Z","shell.execute_reply":"2021-06-26T17:03:28.708868Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"X = encode_query_passage(tokenizer, dicts, model_config, data_config)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T17:03:31.169772Z","iopub.execute_input":"2021-06-26T17:03:31.170310Z","iopub.status.idle":"2021-06-26T17:05:36.859271Z","shell.execute_reply.started":"2021-06-26T17:03:31.170276Z","shell.execute_reply":"2021-06-26T17:05:36.858203Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n  import sys\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/60000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b4684756ba74627852d8ac08e4c0b3c"}},"metadata":{}},{"name":"stdout","text":"len queries: 60000\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"code","source":"from transformers import create_optimizer","metadata":{"execution":{"iopub.status.busy":"2021-06-26T17:05:36.909590Z","iopub.execute_input":"2021-06-26T17:05:36.910270Z","iopub.status.idle":"2021-06-26T17:05:36.920573Z","shell.execute_reply.started":"2021-06-26T17:05:36.910212Z","shell.execute_reply":"2021-06-26T17:05:36.916957Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class QueryModel(tf.keras.Model):\n    def __init__(self, model_config, **kwargs):\n        super().__init__(**kwargs)\n        self.query_encoder = TFAutoModel.from_pretrained(model_config.model_name, from_pt=True)\n        self.dropout = tf.keras.layers.Dropout(model_config.dropout)\n        \n    def call(self, inputs, training=False, **kwargs):\n        \n        pooled_output = self.query_encoder(inputs, training=training, **kwargs)[1]\n        pooled_output = self.dropout(pooled_output, training=training)\n        print(\"Q pooled_output :\",pooled_output.shape)\n        return pooled_output","metadata":{"execution":{"iopub.status.busy":"2021-06-26T17:05:36.923212Z","iopub.execute_input":"2021-06-26T17:05:36.923757Z","iopub.status.idle":"2021-06-26T17:05:36.936547Z","shell.execute_reply.started":"2021-06-26T17:05:36.923708Z","shell.execute_reply":"2021-06-26T17:05:36.934250Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class PassageModel(tf.keras.Model):\n    def __init__(self, model_config, **kwargs):\n        super().__init__(**kwargs)\n        self.passage_encoder = TFAutoModel.from_pretrained(model_config.model_name, from_pt=True)\n        self.dropout = tf.keras.layers.Dropout(model_config.dropout)\n        \n    def call(self, inputs, training=False, **kwargs):\n   \n        pooled_output = self.passage_encoder(inputs, training=training, **kwargs)[1]\n        pooled_output = self.dropout(pooled_output, training=training)\n        print(\"P pooled_output :\", pooled_output.shape)\n        return pooled_output","metadata":{"execution":{"iopub.status.busy":"2021-06-26T17:05:38.336495Z","iopub.execute_input":"2021-06-26T17:05:38.336869Z","iopub.status.idle":"2021-06-26T17:05:38.343948Z","shell.execute_reply.started":"2021-06-26T17:05:38.336832Z","shell.execute_reply":"2021-06-26T17:05:38.342737Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def cross_replica_concat(values, v_shape):\n\n    context = tf.distribute.get_replica_context()\n    gathered = context.all_gather(values, axis=0)\n\n    return tf.roll(\n      gathered,\n      -context.replica_id_in_sync_group * values.shape[0], #v_shape,#values.shape[0],\n      axis=0\n    )\n\nclass BiEncoderModel(tf.keras.Model):\n    def __init__(self, query_encoder, passage_encoder, num_passages_per_question, model_config, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        \n        self.query_encoder = query_encoder\n        self.passage_encoder = passage_encoder\n        self.num_passages_per_question = num_passages_per_question\n        self.model_config = model_config\n        \n        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n        self.loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE, from_logits=True)\n        \n    def calculate_loss(self, logits):\n        \n        num_queries = tf.shape(logits)[0]\n        num_candidates = tf.shape(logits)[1]\n        \n        labels = tf.convert_to_tensor([i for i in range(0,(GLOBAL_BATCH_SIZE*self.num_passages_per_question),self.num_passages_per_question)])\n        \n        loss = self.loss_fn(labels, logits)\n        scale_loss = tf.reduce_sum(loss) * (1. / GLOBAL_BATCH_SIZE)\n        return scale_loss\n    \n    def passage_forward(self, X):\n        input_shape = (self.model_config.batch_size_per_replica * self.num_passages_per_question, self.model_config.passage_max_seq_len)\n        input_ids = tf.reshape(X[\"passage_input_ids\"], input_shape)\n        attention_mask = tf.reshape(X[\"passage_attention_mask\"], input_shape)\n        token_type_ids = tf.reshape(X[\"passage_token_type_ids\"], input_shape)\n        outputs = self.passage_encoder([input_ids, attention_mask, token_type_ids], training=True)\n        return outputs\n\n\n    def query_forward(self, X):\n        input_shape = (self.model_config.batch_size_per_replica, self.model_config.query_max_seq_len)\n        input_ids = tf.reshape(X[\"query_input_ids\"], input_shape)\n        attention_mask = tf.reshape(X[\"query_attention_mask\"], input_shape)\n        token_type_ids = tf.reshape(X[\"query_token_type_ids\"], input_shape)\n        outputs = self.query_encoder([input_ids, attention_mask, token_type_ids], training=True)\n        return outputs\n    \n    def train_step(self, X):\n        \n        with tf.GradientTape() as tape:\n            passage_embeddings = self.passage_forward(X)\n            query_embeddings = self.query_forward(X)\n            \n            global_passage_embeddings = cross_replica_concat(passage_embeddings, 32)\n            global_query_embeddings = cross_replica_concat(query_embeddings, 16)\n            \n            print(\"Global Passage Shape :\", global_passage_embeddings.shape)\n            print(\"Global Query Shape :\", global_query_embeddings.shape)\n            \n            similarity_scores = tf.linalg.matmul(global_query_embeddings, global_passage_embeddings, transpose_b=True)\n            \n            loss = self.calculate_loss(similarity_scores)\n            loss = loss / strategy.num_replicas_in_sync\n            \n        # Backward pass\n        gradients = tape.gradient(loss, self.trainable_variables)\n        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n        # Monitor loss\n        self.loss_tracker.update_state(loss)\n        return {\"loss\": self.loss_tracker.result()}\n    \n    @property\n    def metrics(self):\n        return [self.loss_tracker]","metadata":{"execution":{"iopub.status.busy":"2021-06-26T17:05:40.345200Z","iopub.execute_input":"2021-06-26T17:05:40.345642Z","iopub.status.idle":"2021-06-26T17:05:40.366968Z","shell.execute_reply.started":"2021-06-26T17:05:40.345606Z","shell.execute_reply":"2021-06-26T17:05:40.365630Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE_PER_REPLICA = model_config.batch_size_per_replica\nGLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\nN_EPOCHS = model_config.epochs\none_epoch_steps = int(len(dicts)/GLOBAL_BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T17:05:42.148773Z","iopub.execute_input":"2021-06-26T17:05:42.149146Z","iopub.status.idle":"2021-06-26T17:05:42.154151Z","shell.execute_reply.started":"2021-06-26T17:05:42.149116Z","shell.execute_reply":"2021-06-26T17:05:42.153015Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"one_epoch_steps, N_EPOCHS, BATCH_SIZE_PER_REPLICA, GLOBAL_BATCH_SIZE","metadata":{"execution":{"iopub.status.busy":"2021-06-26T17:05:42.588430Z","iopub.execute_input":"2021-06-26T17:05:42.588831Z","iopub.status.idle":"2021-06-26T17:05:42.596127Z","shell.execute_reply.started":"2021-06-26T17:05:42.588791Z","shell.execute_reply":"2021-06-26T17:05:42.595051Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(58, 40, 128, 1024)"},"metadata":{}}]},{"cell_type":"code","source":"with strategy.scope():\n    query_encoder = QueryModel(model_config)\n    passage_encoder = PassageModel(model_config)\n    bi_model = BiEncoderModel(query_encoder, passage_encoder, num_passages_per_question=data_config.num_positives+data_config.num_hard_negatives, model_config=model_config)\n    optimizer, lr_schedule = create_optimizer(init_lr=model_config.learning_rate, num_train_steps=N_EPOCHS*one_epoch_steps, num_warmup_steps=(N_EPOCHS*one_epoch_steps)*0.1)\n    bi_model.compile(optimizer=optimizer)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T17:05:52.328706Z","iopub.execute_input":"2021-06-26T17:05:52.329249Z","iopub.status.idle":"2021-06-26T17:06:00.580742Z","shell.execute_reply.started":"2021-06-26T17:05:52.329214Z","shell.execute_reply":"2021-06-26T17:06:00.579594Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\nSome weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"with strategy.scope():\n    train_ds = tf.data.Dataset.from_tensor_slices(X).shuffle(GLOBAL_BATCH_SIZE * 10).prefetch(buffer_size=tf.data.experimental.AUTOTUNE).batch(GLOBAL_BATCH_SIZE, drop_remainder=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T17:06:03.965766Z","iopub.execute_input":"2021-06-26T17:06:03.966178Z","iopub.status.idle":"2021-06-26T17:06:06.296852Z","shell.execute_reply.started":"2021-06-26T17:06:03.966136Z","shell.execute_reply":"2021-06-26T17:06:06.295761Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"bi_model.fit(train_ds, epochs=N_EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T17:06:10.908913Z","iopub.execute_input":"2021-06-26T17:06:10.909303Z","iopub.status.idle":"2021-06-26T17:25:25.843736Z","shell.execute_reply.started":"2021-06-26T17:06:10.909267Z","shell.execute_reply":"2021-06-26T17:25:25.842765Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Epoch 1/40\nP pooled_output : (512, 512)\nQ pooled_output : (128, 512)\nGlobal Passage Shape : (4096, 512)\nGlobal Query Shape : (1024, 512)\nP pooled_output : (512, 512)\nQ pooled_output : (128, 512)\nGlobal Passage Shape : (4096, 512)\nGlobal Query Shape : (1024, 512)\n58/58 [==============================] - 85s 451ms/step - loss: 5.4331\nEpoch 2/40\n58/58 [==============================] - 26s 452ms/step - loss: 1.7092\nEpoch 3/40\n58/58 [==============================] - 26s 453ms/step - loss: 1.1920\nEpoch 4/40\n58/58 [==============================] - 26s 452ms/step - loss: 0.9585\nEpoch 5/40\n58/58 [==============================] - 26s 452ms/step - loss: 0.7851\nEpoch 6/40\n58/58 [==============================] - 26s 454ms/step - loss: 0.6400\nEpoch 7/40\n58/58 [==============================] - 26s 452ms/step - loss: 0.5393\nEpoch 8/40\n58/58 [==============================] - 26s 452ms/step - loss: 0.4755\nEpoch 9/40\n58/58 [==============================] - 26s 452ms/step - loss: 0.4338\nEpoch 10/40\n58/58 [==============================] - 26s 452ms/step - loss: 0.4078\nEpoch 11/40\n58/58 [==============================] - 26s 452ms/step - loss: 0.3864\nEpoch 12/40\n58/58 [==============================] - 26s 452ms/step - loss: 0.3687\nEpoch 13/40\n58/58 [==============================] - 26s 452ms/step - loss: 0.3563\nEpoch 14/40\n58/58 [==============================] - 26s 452ms/step - loss: 0.3440\nEpoch 15/40\n58/58 [==============================] - 26s 452ms/step - loss: 0.3339\nEpoch 16/40\n58/58 [==============================] - 26s 452ms/step - loss: 0.3240\nEpoch 17/40\n58/58 [==============================] - 26s 453ms/step - loss: 0.3170\nEpoch 18/40\n58/58 [==============================] - 26s 452ms/step - loss: 0.3100\nEpoch 19/40\n58/58 [==============================] - 26s 452ms/step - loss: 0.3020\nEpoch 20/40\n58/58 [==============================] - 26s 452ms/step - loss: 0.2954\nEpoch 21/40\n58/58 [==============================] - 26s 452ms/step - loss: 0.2908\nEpoch 22/40\n58/58 [==============================] - 26s 453ms/step - loss: 0.2865\nEpoch 23/40\n58/58 [==============================] - 26s 452ms/step - loss: 0.2819\nEpoch 24/40\n58/58 [==============================] - 26s 452ms/step - loss: 0.2773\nEpoch 25/40\n58/58 [==============================] - 26s 452ms/step - loss: 0.2736\nEpoch 26/40\n58/58 [==============================] - 26s 452ms/step - loss: 0.2699\nEpoch 27/40\n58/58 [==============================] - 26s 452ms/step - loss: 0.2656\nEpoch 28/40\n58/58 [==============================] - 26s 452ms/step - loss: 0.2634\nEpoch 29/40\n58/58 [==============================] - 26s 452ms/step - loss: 0.2586\nEpoch 30/40\n58/58 [==============================] - 26s 452ms/step - loss: 0.2583\nEpoch 31/40\n58/58 [==============================] - 26s 452ms/step - loss: 0.2552\nEpoch 32/40\n58/58 [==============================] - 26s 452ms/step - loss: 0.2523\nEpoch 33/40\n58/58 [==============================] - 26s 452ms/step - loss: 0.2514\nEpoch 34/40\n58/58 [==============================] - 26s 452ms/step - loss: 0.2477\nEpoch 35/40\n58/58 [==============================] - 26s 452ms/step - loss: 0.2476\nEpoch 36/40\n58/58 [==============================] - 26s 452ms/step - loss: 0.2468\nEpoch 37/40\n58/58 [==============================] - 26s 452ms/step - loss: 0.2461\nEpoch 38/40\n58/58 [==============================] - 26s 452ms/step - loss: 0.2433\nEpoch 39/40\n58/58 [==============================] - 26s 452ms/step - loss: 0.2431\nEpoch 40/40\n58/58 [==============================] - 26s 452ms/step - loss: 0.2438\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7fc0d059a750>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"!wget https://dl.fbaipublicfiles.com/dpr/data/retriever/biencoder-nq-dev.json.gz\n!gunzip biencoder-nq-dev.json.gz","metadata":{"execution":{"iopub.status.busy":"2021-06-26T17:25:34.229363Z","iopub.execute_input":"2021-06-26T17:25:34.229753Z","iopub.status.idle":"2021-06-26T17:26:07.056290Z","shell.execute_reply.started":"2021-06-26T17:25:34.229723Z","shell.execute_reply":"2021-06-26T17:26:07.054764Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"--2021-06-26 17:25:34--  https://dl.fbaipublicfiles.com/dpr/data/retriever/biencoder-nq-dev.json.gz\nResolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.74.142, 104.22.75.142, ...\nConnecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 256239282 (244M) [application/gzip]\nSaving to: ‘biencoder-nq-dev.json.gz’\n\nbiencoder-nq-dev.js 100%[===================>] 244.37M  11.7MB/s    in 22s     \n\n2021-06-26 17:25:58 (11.0 MB/s) - ‘biencoder-nq-dev.json.gz’ saved [256239282/256239282]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"eval_dicts = read_dpr_json(\"biencoder-nq-dev.json\", num_hard_negatives=30, shuffle_negatives=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T17:26:07.058685Z","iopub.execute_input":"2021-06-26T17:26:07.059074Z","iopub.status.idle":"2021-06-26T17:26:13.917170Z","shell.execute_reply.started":"2021-06-26T17:26:07.059037Z","shell.execute_reply":"2021-06-26T17:26:13.916012Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n  del sys.path[0]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6515 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efddbaf0d75a40b3b27541568c87badc"}},"metadata":{}}]},{"cell_type":"code","source":"def combine_title_context(titles, texts):\n    res = []\n    for title, ctx in zip(titles, texts):\n        if title is None:\n            title = \"\"\n        res.append(tuple((title, ctx)))\n    return res\n\ndef process_single_example(passages):\n    answer_index = -1\n    titles = []\n    texts = []\n    for i in range(len(passages)):\n        p = passages[i]\n        titles.append(p['title'])\n        texts.append(p['text'])\n        if p['label']==\"positive\":\n            answer_index = i\n\n    res = combine_title_context(titles, texts)\n\n    return res, answer_index\n\ndef process_examples(dicts):\n    processed_passages = []\n    queries = []\n    answer_indexes = []\n    global_answer_index = 0\n\n    for i in range(len(dicts)):\n        dict_ = dicts[i]\n        query = dict_[\"query\"]\n        queries.append(query)\n\n        passages = dict_[\"passages\"]\n        res, answer_index = process_single_example(passages)\n\n        i_answer_index = global_answer_index + answer_index\n\n        processed_passages.extend(res)\n        answer_indexes.append(i_answer_index)\n\n        global_answer_index = global_answer_index + len(passages)\n    return queries, answer_indexes, processed_passages","metadata":{"execution":{"iopub.status.busy":"2021-06-26T17:26:18.534602Z","iopub.execute_input":"2021-06-26T17:26:18.534973Z","iopub.status.idle":"2021-06-26T17:26:18.546506Z","shell.execute_reply.started":"2021-06-26T17:26:18.534943Z","shell.execute_reply":"2021-06-26T17:26:18.545413Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"queries, answer_indexes, processed_passages = process_examples(eval_dicts)\nlen(processed_passages), len(queries)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T17:26:13.968711Z","iopub.execute_input":"2021-06-26T17:26:13.969063Z","iopub.status.idle":"2021-06-26T17:26:14.211530Z","shell.execute_reply.started":"2021-06-26T17:26:13.969029Z","shell.execute_reply":"2021-06-26T17:26:14.210422Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"(199795, 6445)"},"metadata":{}}]},{"cell_type":"code","source":"def extracted_passage_embeddings(processed_passages, model_config):\n    passage_inputs = tokenizer.batch_encode_plus(\n                    processed_passages,\n                    add_special_tokens=True,\n                    truncation=True,\n                    padding=\"max_length\",\n                    max_length=model_config.passage_max_seq_len,\n                    return_token_type_ids=True\n                )\n    passage_embeddings = passage_encoder.predict([np.array(passage_inputs['input_ids']), \n                                                np.array(passage_inputs['attention_mask']), \n                                                np.array(passage_inputs['token_type_ids'])], \n                                                batch_size=512, \n                                                verbose=1)\n    return passage_embeddings","metadata":{"execution":{"iopub.status.busy":"2021-06-26T17:26:23.069328Z","iopub.execute_input":"2021-06-26T17:26:23.069712Z","iopub.status.idle":"2021-06-26T17:26:23.076923Z","shell.execute_reply.started":"2021-06-26T17:26:23.069681Z","shell.execute_reply":"2021-06-26T17:26:23.076037Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"passage_embeddings = extracted_passage_embeddings(processed_passages, model_config)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T17:26:25.628527Z","iopub.execute_input":"2021-06-26T17:26:25.628895Z","iopub.status.idle":"2021-06-26T17:28:05.146703Z","shell.execute_reply.started":"2021-06-26T17:26:25.628865Z","shell.execute_reply":"2021-06-26T17:28:05.145620Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"P pooled_output : (None, 512)\n391/391 [==============================] - 22s 50ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"def extracted_query_embeddings(queries, model_config):\n    query_inputs = tokenizer.batch_encode_plus(\n                    queries,\n                    add_special_tokens=True,\n                    truncation=True,\n                    padding=\"max_length\",\n                    max_length=model_config.query_max_seq_len,\n                    return_token_type_ids=True\n                )\n    query_embeddings = query_encoder.predict([np.array(query_inputs['input_ids']), \n                                                np.array(query_inputs['attention_mask']), \n                                                np.array(query_inputs['token_type_ids'])], \n                                                batch_size=512, \n                                                verbose=1)\n    return query_embeddings","metadata":{"execution":{"iopub.status.busy":"2021-06-26T17:28:23.645547Z","iopub.execute_input":"2021-06-26T17:28:23.645989Z","iopub.status.idle":"2021-06-26T17:28:23.653023Z","shell.execute_reply.started":"2021-06-26T17:28:23.645952Z","shell.execute_reply":"2021-06-26T17:28:23.651822Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"query_embeddings = extracted_query_embeddings(queries, model_config)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T17:28:23.916143Z","iopub.execute_input":"2021-06-26T17:28:23.916557Z","iopub.status.idle":"2021-06-26T17:28:32.889171Z","shell.execute_reply.started":"2021-06-26T17:28:23.916526Z","shell.execute_reply":"2021-06-26T17:28:32.887789Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Q pooled_output : (None, 512)\n13/13 [==============================] - 8s 526ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"import faiss\nfaiss_index = faiss.IndexFlatL2(512)\nfaiss_index.add(passage_embeddings)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T17:29:12.857704Z","iopub.execute_input":"2021-06-26T17:29:12.858102Z","iopub.status.idle":"2021-06-26T17:29:13.384977Z","shell.execute_reply.started":"2021-06-26T17:29:12.858062Z","shell.execute_reply":"2021-06-26T17:29:13.383727Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def get_k_accuracy(faiss_index, query_embeddings, answer_indexes, k):\n\n    prob, index = faiss_index.search(query_embeddings, k=k)\n\n    corrects = []\n    for i in tqdm_notebook(range(len(answer_indexes))):\n      i_index = index[i]\n      i_count = len(np.where(i_index == answer_indexes[i])[0])\n      if i_count >0:\n            corrects.append((i, answer_indexes[i]))\n    return corrects","metadata":{"execution":{"iopub.status.busy":"2021-06-26T17:29:16.976443Z","iopub.execute_input":"2021-06-26T17:29:16.976790Z","iopub.status.idle":"2021-06-26T17:29:16.983718Z","shell.execute_reply.started":"2021-06-26T17:29:16.976762Z","shell.execute_reply":"2021-06-26T17:29:16.982530Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"top10_corrects = get_k_accuracy(faiss_index, query_embeddings, answer_indexes, k=10)\ntop20_corrects = get_k_accuracy(faiss_index, query_embeddings, answer_indexes, k=20)\ntop50_corrects = get_k_accuracy(faiss_index, query_embeddings, answer_indexes, k=50)\ntop100_corrects = get_k_accuracy(faiss_index, query_embeddings, answer_indexes, k=100)\ntop1000_corrects = get_k_accuracy(faiss_index, query_embeddings, answer_indexes, k=1000)","metadata":{"execution":{"iopub.status.busy":"2021-06-26T17:29:19.777560Z","iopub.execute_input":"2021-06-26T17:29:19.777921Z","iopub.status.idle":"2021-06-26T17:30:00.250693Z","shell.execute_reply.started":"2021-06-26T17:29:19.777891Z","shell.execute_reply":"2021-06-26T17:30:00.249663Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n  \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6445 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9390f86c34a047faa246a802a8cbef72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6445 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"979aceff4d894dee8b0e50565a34503c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6445 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62aa3b4ee28246c4a4f448f13e851b2a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6445 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96f40e1aad4444498d0359b3925308ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/6445 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a86e062c899b4955846f2fcbc114faa9"}},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nresults = pd.DataFrame({'topK':[10,20,50,100,1000],\n                       'total':[len(query_embeddings)]*5,\n                       'correct_total':[len(top10_corrects), len(top20_corrects), len(top50_corrects), len(top100_corrects), len(top1000_corrects)]})\n\nresults['accuracy'] = (results['correct_total'] / results['total'])*100\nresults","metadata":{"execution":{"iopub.status.busy":"2021-06-26T17:30:03.126449Z","iopub.execute_input":"2021-06-26T17:30:03.126863Z","iopub.status.idle":"2021-06-26T17:30:03.184234Z","shell.execute_reply.started":"2021-06-26T17:30:03.126823Z","shell.execute_reply":"2021-06-26T17:30:03.183435Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"   topK  total  correct_total   accuracy\n0    10   6445           1153  17.889837\n1    20   6445           1748  27.121800\n2    50   6445           2631  40.822343\n3   100   6445           3311  51.373157\n4  1000   6445           5293  82.125679","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topK</th>\n      <th>total</th>\n      <th>correct_total</th>\n      <th>accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10</td>\n      <td>6445</td>\n      <td>1153</td>\n      <td>17.889837</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20</td>\n      <td>6445</td>\n      <td>1748</td>\n      <td>27.121800</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>50</td>\n      <td>6445</td>\n      <td>2631</td>\n      <td>40.822343</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100</td>\n      <td>6445</td>\n      <td>3311</td>\n      <td>51.373157</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000</td>\n      <td>6445</td>\n      <td>5293</td>\n      <td>82.125679</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}